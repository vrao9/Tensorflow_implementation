# -*- coding: utf-8 -*-
"""pix2pix_tf_tutorial_sot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tYguFQUVPhvBp-av3x-qTB-QnJIKtxCJ
"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU
from tensorflow.keras.layers import ReLU, Conv2DTranspose, Dropout, Input
from tensorflow.keras.activations import tanh, sigmoid
from tensorflow.losses import sigmoid_cross_entropy, absolute_difference
import time
import numpy as np

!rm -R /content/logs

tf.enable_eager_execution()
print(tf.__version__)

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from google.colab import drive
drive.mount('/content/drive')

# warning: run this only once!!
# log_dir=f'logs/{NAME}'
log_dir='logs'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(log_dir)
)
! curl http://localhost:6006
! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1
! unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1
get_ipython().system_raw('./ngrok http 6006 &')
! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"

def scale_img(rgb_img, nir_img):
    # cast to float
    rgb_img = tf.cast(rgb_img, tf.float32)
    nir_img = tf.cast(nir_img, tf.float32)
    # scale between -1 and +1
    rgb_img = rgb_img/127.5 - 1.0
    nir_img = nir_img/127.5 - 1.0
    return rgb_img, nir_img


def crop_img(rgb_img, nir_img):
    combined_img = tf.concat([rgb_img, nir_img], axis=2)
    combined_img_cropped = tf.random_crop(combined_img, size=[256, 256, 4])
    # rgb_cropped = tf.random_crop(rgb_img, size=[256, 256, 3])
    # nir_cropped = tf.random_crop(nir_img, size=[256, 256, 1])
    rgb_cropped = combined_img_cropped[:, :, :3]
    nir_cropped = combined_img_cropped[:, :, 3]
    nir_cropped = nir_cropped[..., np.newaxis]
    return rgb_cropped, nir_cropped


def _parse_image_function(example):
    # Create a dictionary describing the features
    image_feature_description = {
        'height': tf.FixedLenFeature([], tf.int64),
        'width': tf.FixedLenFeature([], tf.int64),
        'channel': tf.FixedLenFeature([], tf.int64),
        'rgb_image': tf.FixedLenFeature([], tf.string),
        'nir_image': tf.FixedLenFeature([], tf.string),
    }
    # Parse the input tf.Example proto using the dictionary above.
    example = tf.parse_single_example(example, image_feature_description)
    decoded_rgb_img = tf.image.decode_png(example['rgb_image'])
    decoded_nir_img = tf.image.decode_png(example['nir_image'])
    return decoded_rgb_img, decoded_nir_img


def load_tf_record(tf_filename):
    raw_img_dataset = tf.data.TFRecordDataset(tf_filename)
    png_img_dataset = raw_img_dataset.map(_parse_image_function)
    png_img_dataset = png_img_dataset.map(crop_img)
    png_img_dataset = png_img_dataset.map(scale_img)
    return png_img_dataset


def get_training_dataset(tf_filename, batch_size):
    dataset = load_tf_record(tf_filename)
    dataset = dataset.shuffle(100, reshuffle_each_iteration=True)
    # drop_remainder = True will discard the remaining dataset which
    # is not divisble by the batch size
    # inorder to have better control of the epoch, batch is created and then
    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)
    # specify the number of times the dataset should be repeated
    # if no param passed, will loop for ever
    dataset = dataset.repeat()
    
    # -1 would auto tune the prefetch buffer size
    dataset = dataset.prefetch(-1)
    return dataset


def get_validation_dataset(tf_filename, batch_size):
    dataset = load_tf_record(tf_filename)
    # this small dataset can be entirely cached in RAM, for TPU this is 
    # important to get good performance from such a small dataset
    # dataset = dataset.cache()
    dataset = dataset.batch(batch_size=batch_size, drop_remainder=True)
    dataset = dataset.repeat() 
    return dataset

class Downsample(tf.keras.Model):
    
    def __init__(self, filters, size, apply_batchnorm=True):
        super(Downsample, self).__init__()
        self.apply_batchnorm = apply_batchnorm
        initializer = tf.random_normal_initializer(0., 0.02)

        self.conv1 = tf.keras.layers.Conv2D(filters, 
                                            (size, size), 
                                            strides=2, 
                                            padding='same',
                                            kernel_initializer=initializer,
                                            use_bias=False)
        if self.apply_batchnorm:
            self.batchnorm = tf.keras.layers.BatchNormalization()
  
    def call(self, x, training):
        x = self.conv1(x)
        if self.apply_batchnorm:
            x = self.batchnorm(x, training=training)
        x = tf.nn.leaky_relu(x)
        return x 


class Upsample(tf.keras.Model):
    
    def __init__(self, filters, size, apply_dropout=False):
        super(Upsample, self).__init__()
        self.apply_dropout = apply_dropout
        initializer = tf.random_normal_initializer(0., 0.02)

        self.up_conv = tf.keras.layers.Conv2DTranspose(filters, 
                                                       (size, size), 
                                                       strides=2, 
                                                       padding='same',
                                                       kernel_initializer=initializer,
                                                       use_bias=False)
        self.batchnorm = tf.keras.layers.BatchNormalization()
        if self.apply_dropout:
            self.dropout = tf.keras.layers.Dropout(0.5)

    def call(self, x1, x2, training):
        x = self.up_conv(x1)
        x = self.batchnorm(x, training=training)
        if self.apply_dropout:
            x = self.dropout(x, training=training)
        x = tf.nn.relu(x)
        x = tf.concat([x, x2], axis=-1)
        return x


class Generator(tf.keras.Model):
    
    def __init__(self):
        super(Generator, self).__init__()
        initializer = tf.random_normal_initializer(0., 0.02)

        self.down1 = Downsample(64, 4, apply_batchnorm=False)
        self.down2 = Downsample(128, 4)
        self.down3 = Downsample(256, 4)
        self.down4 = Downsample(512, 4)
        self.down5 = Downsample(512, 4)
        self.down6 = Downsample(512, 4)
        self.down7 = Downsample(512, 4)
        self.down8 = Downsample(512, 4)

        self.up1 = Upsample(512, 4, apply_dropout=True)
        self.up2 = Upsample(512, 4, apply_dropout=True)
        self.up3 = Upsample(512, 4, apply_dropout=True)
        self.up4 = Upsample(512, 4)
        self.up5 = Upsample(256, 4)
        self.up6 = Upsample(128, 4)
        self.up7 = Upsample(64, 4)

        self.last = tf.keras.layers.Conv2DTranspose(1, 
                                                    (4, 4), 
                                                    strides=2, 
                                                    padding='same',
                                                    kernel_initializer=initializer)


    def call(self, x, training):
        # x shape == (bs, 256, 256, 3)    
        x1 = self.down1(x, training=training) # (bs, 128, 128, 64)
        x2 = self.down2(x1, training=training) # (bs, 64, 64, 128)
        x3 = self.down3(x2, training=training) # (bs, 32, 32, 256)
        x4 = self.down4(x3, training=training) # (bs, 16, 16, 512)
        x5 = self.down5(x4, training=training) # (bs, 8, 8, 512)
        x6 = self.down6(x5, training=training) # (bs, 4, 4, 512)
        x7 = self.down7(x6, training=training) # (bs, 2, 2, 512)
        x8 = self.down8(x7, training=training) # (bs, 1, 1, 512)

        x9 = self.up1(x8, x7, training=training) # (bs, 2, 2, 1024)
        x10 = self.up2(x9, x6, training=training) # (bs, 4, 4, 1024)
        x11 = self.up3(x10, x5, training=training) # (bs, 8, 8, 1024)
        x12 = self.up4(x11, x4, training=training) # (bs, 16, 16, 1024)
        x13 = self.up5(x12, x3, training=training) # (bs, 32, 32, 512)
        x14 = self.up6(x13, x2, training=training) # (bs, 64, 64, 256)
        x15 = self.up7(x14, x1, training=training) # (bs, 128, 128, 128)

        x16 = self.last(x15) # (bs, 256, 256, 3)
        x16 = tf.nn.tanh(x16)

        return x16

class DiscDownsample(tf.keras.Model):
    
    def __init__(self, filters, size, apply_batchnorm=True):
        super(DiscDownsample, self).__init__()
        self.apply_batchnorm = apply_batchnorm
        initializer = tf.random_normal_initializer(0., 0.02)

        self.conv1 = tf.keras.layers.Conv2D(filters, 
                                            (size, size), 
                                            strides=2, 
                                            padding='same',
                                            kernel_initializer=initializer,
                                            use_bias=False)
        if self.apply_batchnorm:
            self.batchnorm = tf.keras.layers.BatchNormalization()
  
    def call(self, x, training):
        x = self.conv1(x)
        if self.apply_batchnorm:
            x = self.batchnorm(x, training=training)
        x = tf.nn.leaky_relu(x)
        return x 

class Discriminator(tf.keras.Model):
    
    def __init__(self):
        super(Discriminator, self).__init__()
        initializer = tf.random_normal_initializer(0., 0.02)

        self.down1 = DiscDownsample(64, 4, False)
        self.down2 = DiscDownsample(128, 4)
        self.down3 = DiscDownsample(256, 4)

        # we are zero padding here with 1 because we need our shape to 
        # go from (batch_size, 32, 32, 256) to (batch_size, 31, 31, 512)
        self.zero_pad1 = tf.keras.layers.ZeroPadding2D()
        self.conv = tf.keras.layers.Conv2D(512, 
                                           (4, 4), 
                                           strides=1, 
                                           kernel_initializer=initializer, 
                                           use_bias=False)
        self.batchnorm1 = tf.keras.layers.BatchNormalization()

        # shape change from (batch_size, 31, 31, 512) to (batch_size, 30, 30, 1)
        self.zero_pad2 = tf.keras.layers.ZeroPadding2D()
        self.last = tf.keras.layers.Conv2D(1, 
                                           (4, 4), 
                                           strides=1,
                                           kernel_initializer=initializer)


    def call(self, x, training):
        # concatenating the input and the target
        x = self.down1(x, training=training) # (bs, 128, 128, 64)
        x = self.down2(x, training=training) # (bs, 64, 64, 128)
        x = self.down3(x, training=training) # (bs, 32, 32, 256)

        x = self.zero_pad1(x) # (bs, 34, 34, 256)
        x = self.conv(x)      # (bs, 31, 31, 512)
        x = self.batchnorm1(x, training=training)
        x = tf.nn.leaky_relu(x)

        x = self.zero_pad2(x) # (bs, 33, 33, 512)
        # don't add a sigmoid activation here since
        # the loss function expects raw logits.
        x = self.last(x)      # (bs, 30, 30, 1)

        return x

def discriminator_loss(disc_real_output, disc_generated_output):
    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(disc_real_output), 
                                              logits = disc_real_output)
    generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.zeros_like(disc_generated_output), 
                                                   logits = disc_generated_output)

    total_disc_loss = real_loss + generated_loss

    return total_disc_loss

def generator_loss(disc_generated_output, gen_output, target):
    gan_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(disc_generated_output),
                                             logits = disc_generated_output) 
    # mean absolute error
    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))

    total_gen_loss = gan_loss + (100 * l1_loss)

    return total_gen_loss

def tensorboard_call(writer, epoch, y_fake_prob, y_real_prob, disc_loss, gen_loss):
    with writer.as_default(), tf.contrib.summary.always_record_summaries():
            tf.contrib.summary.scalar("y_fake_prob", y_fake_prob,
                                      step=tf.cast(epoch, 'int64'))
            tf.contrib.summary.scalar("y_real_prob", y_real_prob,
                                      step=tf.cast(epoch, 'int64'))
            tf.contrib.summary.scalar("disc_loss", disc_loss,
                                      step=tf.cast(epoch, 'int64'))
            tf.contrib.summary.scalar("gen_loss", gen_loss,
                                      step=tf.cast(epoch, 'int64'))

if __name__ == "__main__":
    no_samples = 427
    batch_size = 32
    no_batches = no_samples//batch_size
    tf_filename_train = 'drive/My Drive/Colab Notebooks/nir_rgb_tfrecord_train.tfrecords'
    tf_filename_val = 'drive/My Drive/Colab Notebooks/nir_rgb_tfrecord_val.tfrecords'

    # [0]:rgb [1]:nir
    train_dataset = get_training_dataset(tf_filename_train, batch_size)
    val_dataset = get_validation_dataset(tf_filename_val, batch_size=50)
    gen_model = Generator()
    disc_model = Discriminator()

    # optimizer
    gen_opt = tf.train.AdamOptimizer(2e-4, beta1=0.5)
    disc_opt = tf.train.AdamOptimizer(2e-4, beta1=0.5)

    # file writter
    NAME = f'pix2pix_{time.strftime("%d%m%y_%H%M")}'
    path = 'drive/My Drive/Colab Notebooks/pix2pix/'
    train_writer = tf.contrib.summary.create_file_writer(f'logs/{NAME}/train')
    val_writer = tf.contrib.summary.create_file_writer(f'logs/{NAME}/val')

    # loss and prob_values
    y_fake_prob_list = np.empty(0)
    y_real_prob_list = np.empty(0)
    gen_loss_list = np.empty(0)
    disc_loss_list = np.empty(0)
    
    # training
    EPOCHS = 100
    gen_losses = []
    global_step = tf.Variable(0)
    begin_epoch_time = time.time()
    for data in train_dataset:
        x = data[0]
        y = data[1]
        with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:
            y_fake = gen_model(x, training=True)
            y_fake_prob_score = disc_model(y_fake, training=True)
            y_real_prob_score = disc_model(y, training=True)
            disc_loss = discriminator_loss(y_real_prob_score, y_fake_prob_score)
            # generator loss
            gen_loss = generator_loss(y_fake_prob_score, y_fake, y)
        
        generator_gradients = gen_tape.gradient(gen_loss, 
                                              gen_model.variables)
        discriminator_gradients = disc_tape.gradient(disc_loss, 
                                                   disc_model.variables)

        gen_opt.apply_gradients(zip(generator_gradients, 
                                              gen_model.variables))
        disc_opt.apply_gradients(zip(discriminator_gradients, 
                                                  disc_model.variables), global_step)

        # store loss and prob values batch wise
        y_fake_prob_list = np.append(y_fake_prob_list,
                                     np.mean(sigmoid(y_fake_prob_score)))
        y_real_prob_list = np.append(y_real_prob_list,
                                     np.mean(sigmoid(y_real_prob_score)))
        disc_loss_list = np.append(disc_loss_list, disc_loss) 
        gen_loss_list = np.append(gen_loss_list, gen_loss)

        # completion of an epoch
        if tf.math.equal(global_step % no_batches, tf.constant(0)):
            end_epoch_time = time.time()
            epoch = global_step//no_batches

            # write train information to tensorboard
            tensorboard_call(train_writer, epoch, np.mean(y_fake_prob_list),
                             np.mean(y_real_prob_list), np.mean(disc_loss_list),
                             np.mean(gen_loss_list))

            # clear all the information in the array
            y_fake_prob_list = np.empty(0)
            y_real_prob_list = np.empty(0)
            gen_loss_list = np.empty(0)
            disc_loss_list = np.empty(0)

            # do the validation
            x_test, y_test = next(iter(val_dataset))
            y_fake = gen_model(x_test, training=False)
            y_fake_prob = disc_model(y_fake, training=False)
            y_real_prob = disc_model(y_test, training=False)
            disc_loss = discriminator_loss(y_real_prob, y_fake_prob)
            gen_loss = generator_loss(y_fake_prob, y_fake, y_test)

            # write validation information to tensorboard
            tensorboard_call(val_writer, epoch, np.mean(sigmoid(y_fake_prob)),
                             np.mean(sigmoid(y_real_prob)), disc_loss,
                             gen_loss)

            print(f'Epoch No: {epoch} Time taken:{end_epoch_time-\
                  begin_epoch_time}')
            print(f'y_fake_prob:{np.mean(sigmoid(y_fake_prob))} '
                  f'y_real_prob:{np.mean(sigmoid(y_real_prob))}')
            print(f'disc_loss:{np.mean(disc_loss)} '
                  f'gen_loss:{np.mean(gen_loss)}')
            '''
            if min(gen_losses, default=np.inf) > gen_loss:
                path = 'drive/My Drive/Colab Notebooks/pix2pix/trained_model'
                checkpoint_path = f'{path}/200_128.hdf5'
                print("loss reduced.. saving the model\n")
                gen_model.save_weights(
                    checkpoint_path,
                    overwrite=True)
            '''
            gen_losses.append(gen_loss)
            begin_epoch_time = time.time()

path = 'drive/My Drive/Colab Notebooks/pix2pix/trained_model'
checkpoint_path = f'{path}/200_128.hdf5'

gen_model.load_weights(checkpoint_path)

import matplotlib.pyplot as plt
import numpy as np
plt.figure(0)
img = plt.imread('./0000_rgb_oldbuilding_.png')
img = img[:512,:,:]
print(img.shape)
plt.imshow(img)
plt.figure(1)
img_scaled = np.interp(img,[0,1],[-1,1])
print(img_scaled.flatten())
plt.hist(img_scaled.flatten(), bins = 100)
plt.show()

print(img_new_axis.astype('float32'))

img_new_axis = img_scaled[np.newaxis,...]
img_new_axis = img_new_axis.astype('float32')
nir_img = gen_model(img_new_axis, training=False)
print(nir_img.shape)
plt.figure(0)
nir_img = nir_img.numpy()
plt.hist(nir_img.flatten(), bins = 100)
nir_img_scaled_back = np.interp(nir_img,[-1,1],[0, 255])
nir_img_scaled_back = np.squeeze(nir_img_scaled_back)
print(nir_img_scaled_back.shape)
img = nir_img_scaled_back.astype(np.uint8)
plt.figure(1)
plt.imshow(img)